{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shelleywang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/shelleywang/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/shelleywang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,\\\n",
    "HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"(?u)\\w{3,}\")\n",
    "stopwords = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocessing(text, tokenizer, stopwords, lemmatizer):\n",
    "    # Lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens =  [token for token in tokens if token not in stopwords]\n",
    "    \n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "      <th>Text</th>\n",
       "      <th>Target</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>list_tokens</th>\n",
       "      <th>string_tokens</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>H_CLINTON</td>\n",
       "      <td>Thank you very much, Chris. And thanks to UNL...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you very much, chris. and thanks to unl...</td>\n",
       "      <td>['thank', 'much', 'chris', 'thanks', 'unlv', '...</td>\n",
       "      <td>thank much chris thanks unlv hosting know thin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>H_CLINTON</td>\n",
       "      <td>Well, thank you. Are you a teacher? Yes, I th...</td>\n",
       "      <td>0</td>\n",
       "      <td>well, thank you. are you a teacher? yes, i th...</td>\n",
       "      <td>['well', 'thank', 'teacher', 'yes', 'think', '...</td>\n",
       "      <td>well thank teacher yes think good question hea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>H_CLINTON</td>\n",
       "      <td>How are you, Donald? [applause]  Well, thank ...</td>\n",
       "      <td>0</td>\n",
       "      <td>how are you, donald? [applause]  well, thank ...</td>\n",
       "      <td>['donald', 'applause', 'well', 'thank', 'leste...</td>\n",
       "      <td>donald applause well thank lester thanks hofst...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996</td>\n",
       "      <td>B_CLINTON</td>\n",
       "      <td>I was going to applaud, too. Well, thank you,...</td>\n",
       "      <td>0</td>\n",
       "      <td>i was going to applaud, too. well, thank you,...</td>\n",
       "      <td>['going', 'applaud', 'well', 'thank', 'jim', '...</td>\n",
       "      <td>going applaud well thank jim thanks people san...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996</td>\n",
       "      <td>B_CLINTON</td>\n",
       "      <td>Thank you, Jim. And thank you to the people o...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you, jim. and thank you to the people o...</td>\n",
       "      <td>['thank', 'jim', 'thank', 'people', 'hartford'...</td>\n",
       "      <td>thank jim thank people hartford host want begi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2005</td>\n",
       "      <td>BUSH_2</td>\n",
       "      <td>Vice President Cheney, Mr. Chief Justice, Pres...</td>\n",
       "      <td>1</td>\n",
       "      <td>vice president cheney, mr. chief justice, pres...</td>\n",
       "      <td>['vice', 'president', 'cheney', 'chief', 'just...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.presidency.ucsb.edu/documents/inau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2009</td>\n",
       "      <td>OBAMA</td>\n",
       "      <td>My fellow citizens, I stand here today humbled...</td>\n",
       "      <td>0</td>\n",
       "      <td>my fellow citizens, i stand here today humbled...</td>\n",
       "      <td>['fellow', 'citizen', 'stand', 'today', 'humbl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.presidency.ucsb.edu/documents/inau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2013</td>\n",
       "      <td>OBAMA</td>\n",
       "      <td>Thank you. Thank you so much. Vice President B...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you. thank you so much. vice president b...</td>\n",
       "      <td>['thank', 'thank', 'much', 'vice', 'president'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.presidency.ucsb.edu/documents/inau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2017</td>\n",
       "      <td>TRUMP</td>\n",
       "      <td>Chief Justice Roberts, President Carter, Presi...</td>\n",
       "      <td>1</td>\n",
       "      <td>chief justice roberts, president carter, presi...</td>\n",
       "      <td>['chief', 'justice', 'robert', 'president', 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.presidency.ucsb.edu/documents/inau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2021</td>\n",
       "      <td>BIDEN</td>\n",
       "      <td>Chief Justice Roberts, Vice President Harris, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>chief justice roberts, vice president harris, ...</td>\n",
       "      <td>['chief', 'justice', 'robert', 'vice', 'presid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.presidency.ucsb.edu/documents/inau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year       Name                                               Text   \n",
       "0    2016  H_CLINTON   Thank you very much, Chris. And thanks to UNL...  \\\n",
       "1    2016  H_CLINTON   Well, thank you. Are you a teacher? Yes, I th...   \n",
       "2    2016  H_CLINTON   How are you, Donald? [applause]  Well, thank ...   \n",
       "3    1996  B_CLINTON   I was going to applaud, too. Well, thank you,...   \n",
       "4    1996  B_CLINTON   Thank you, Jim. And thank you to the people o...   \n",
       "..    ...        ...                                                ...   \n",
       "114  2005     BUSH_2  Vice President Cheney, Mr. Chief Justice, Pres...   \n",
       "115  2009      OBAMA  My fellow citizens, I stand here today humbled...   \n",
       "116  2013      OBAMA  Thank you. Thank you so much. Vice President B...   \n",
       "117  2017      TRUMP  Chief Justice Roberts, President Carter, Presi...   \n",
       "118  2021      BIDEN  Chief Justice Roberts, Vice President Harris, ...   \n",
       "\n",
       "     Target                                         text_lower   \n",
       "0         0   thank you very much, chris. and thanks to unl...  \\\n",
       "1         0   well, thank you. are you a teacher? yes, i th...   \n",
       "2         0   how are you, donald? [applause]  well, thank ...   \n",
       "3         0   i was going to applaud, too. well, thank you,...   \n",
       "4         0   thank you, jim. and thank you to the people o...   \n",
       "..      ...                                                ...   \n",
       "114       1  vice president cheney, mr. chief justice, pres...   \n",
       "115       0  my fellow citizens, i stand here today humbled...   \n",
       "116       0  thank you. thank you so much. vice president b...   \n",
       "117       1  chief justice roberts, president carter, presi...   \n",
       "118       0  chief justice roberts, vice president harris, ...   \n",
       "\n",
       "                                           list_tokens   \n",
       "0    ['thank', 'much', 'chris', 'thanks', 'unlv', '...  \\\n",
       "1    ['well', 'thank', 'teacher', 'yes', 'think', '...   \n",
       "2    ['donald', 'applause', 'well', 'thank', 'leste...   \n",
       "3    ['going', 'applaud', 'well', 'thank', 'jim', '...   \n",
       "4    ['thank', 'jim', 'thank', 'people', 'hartford'...   \n",
       "..                                                 ...   \n",
       "114  ['vice', 'president', 'cheney', 'chief', 'just...   \n",
       "115  ['fellow', 'citizen', 'stand', 'today', 'humbl...   \n",
       "116  ['thank', 'thank', 'much', 'vice', 'president'...   \n",
       "117  ['chief', 'justice', 'robert', 'president', 'c...   \n",
       "118  ['chief', 'justice', 'robert', 'vice', 'presid...   \n",
       "\n",
       "                                         string_tokens   \n",
       "0    thank much chris thanks unlv hosting know thin...  \\\n",
       "1    well thank teacher yes think good question hea...   \n",
       "2    donald applause well thank lester thanks hofst...   \n",
       "3    going applaud well thank jim thanks people san...   \n",
       "4    thank jim thank people hartford host want begi...   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                                  link  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "114  https://www.presidency.ucsb.edu/documents/inau...  \n",
       "115  https://www.presidency.ucsb.edu/documents/inau...  \n",
       "116  https://www.presidency.ucsb.edu/documents/inau...  \n",
       "117  https://www.presidency.ucsb.edu/documents/inau...  \n",
       "118  https://www.presidency.ucsb.edu/documents/inau...  \n",
       "\n",
       "[119 rows x 8 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/final_df.csv')\n",
    "df[\"Target\"] = df[\"Target\"].astype('int')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "      <th>Text</th>\n",
       "      <th>Target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>H_CLINTON</td>\n",
       "      <td>Thank you very much, Chris. And thanks to UNL...</td>\n",
       "      <td>0</td>\n",
       "      <td>[thank, much, chris, thanks, unlv, hosting, kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>H_CLINTON</td>\n",
       "      <td>Well, thank you. Are you a teacher? Yes, I th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[well, thank, teacher, yes, think, good, quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>H_CLINTON</td>\n",
       "      <td>How are you, Donald? [applause]  Well, thank ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[donald, applause, well, thank, lester, thanks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996</td>\n",
       "      <td>B_CLINTON</td>\n",
       "      <td>I was going to applaud, too. Well, thank you,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[going, applaud, well, thank, jim, thanks, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996</td>\n",
       "      <td>B_CLINTON</td>\n",
       "      <td>Thank you, Jim. And thank you to the people o...</td>\n",
       "      <td>0</td>\n",
       "      <td>[thank, jim, thank, people, hartford, host, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2005</td>\n",
       "      <td>BUSH_2</td>\n",
       "      <td>Vice President Cheney, Mr. Chief Justice, Pres...</td>\n",
       "      <td>1</td>\n",
       "      <td>[vice, president, cheney, chief, justice, pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2009</td>\n",
       "      <td>OBAMA</td>\n",
       "      <td>My fellow citizens, I stand here today humbled...</td>\n",
       "      <td>0</td>\n",
       "      <td>[fellow, citizen, stand, today, humbled, task,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2013</td>\n",
       "      <td>OBAMA</td>\n",
       "      <td>Thank you. Thank you so much. Vice President B...</td>\n",
       "      <td>0</td>\n",
       "      <td>[thank, thank, much, vice, president, biden, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2017</td>\n",
       "      <td>TRUMP</td>\n",
       "      <td>Chief Justice Roberts, President Carter, Presi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[chief, justice, robert, president, carter, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2021</td>\n",
       "      <td>BIDEN</td>\n",
       "      <td>Chief Justice Roberts, Vice President Harris, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[chief, justice, robert, vice, president, harr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year       Name                                               Text   \n",
       "0    2016  H_CLINTON   Thank you very much, Chris. And thanks to UNL...  \\\n",
       "1    2016  H_CLINTON   Well, thank you. Are you a teacher? Yes, I th...   \n",
       "2    2016  H_CLINTON   How are you, Donald? [applause]  Well, thank ...   \n",
       "3    1996  B_CLINTON   I was going to applaud, too. Well, thank you,...   \n",
       "4    1996  B_CLINTON   Thank you, Jim. And thank you to the people o...   \n",
       "..    ...        ...                                                ...   \n",
       "114  2005     BUSH_2  Vice President Cheney, Mr. Chief Justice, Pres...   \n",
       "115  2009      OBAMA  My fellow citizens, I stand here today humbled...   \n",
       "116  2013      OBAMA  Thank you. Thank you so much. Vice President B...   \n",
       "117  2017      TRUMP  Chief Justice Roberts, President Carter, Presi...   \n",
       "118  2021      BIDEN  Chief Justice Roberts, Vice President Harris, ...   \n",
       "\n",
       "     Target                                             tokens  \n",
       "0         0  [thank, much, chris, thanks, unlv, hosting, kn...  \n",
       "1         0  [well, thank, teacher, yes, think, good, quest...  \n",
       "2         0  [donald, applause, well, thank, lester, thanks...  \n",
       "3         0  [going, applaud, well, thank, jim, thanks, peo...  \n",
       "4         0  [thank, jim, thank, people, hartford, host, wa...  \n",
       "..      ...                                                ...  \n",
       "114       1  [vice, president, cheney, chief, justice, pres...  \n",
       "115       0  [fellow, citizen, stand, today, humbled, task,...  \n",
       "116       0  [thank, thank, much, vice, president, biden, c...  \n",
       "117       1  [chief, justice, robert, president, carter, pr...  \n",
       "118       0  [chief, justice, robert, vice, president, harr...  \n",
       "\n",
       "[119 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'] = df['Text'].astype(str)\n",
    "tokenized_df = df['Text'].apply((lambda x: preprocessing(x, tokenizer, stopwords, lemmatizer)))\n",
    "df['tokens'] = tokenized_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# X = df[[\"tokens\"]]\n",
    "# y = df[\"Target\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# # make into sparse matrices\n",
    "# vectorizer = CountVectorizer()\n",
    "# X_train = vectorizer.fit_transform(X_train[\"tokens\"].apply(lambda x: \" \".join(x)))\n",
    "# X_test = vectorizer.transform(X_test[\"tokens\"].apply(lambda x: \" \".join(x)))\n",
    "\n",
    "# tfidf = TfidfVectorizer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "\n",
    "# # Naive Bayes\n",
    "\n",
    "# clf = GaussianNB()\n",
    "# clf.fit(X_train_tfidf.toarray(), y_train)\n",
    "# y_pred = clf.predict(X_test_tfidf.toarray())\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "# disp.plot()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52445492 0.47554508]\n",
      " [0.49403541 0.50596459]\n",
      " [0.53109096 0.46890904]\n",
      " [0.60635711 0.39364289]\n",
      " [0.62629435 0.37370565]\n",
      " [0.56299226 0.43700774]\n",
      " [0.43799726 0.56200274]\n",
      " [0.60521568 0.39478432]\n",
      " [0.4738473  0.5261527 ]\n",
      " [0.47626462 0.52373538]\n",
      " [0.48196246 0.51803754]\n",
      " [0.48738851 0.51261149]\n",
      " [0.55838307 0.44161693]\n",
      " [0.52124055 0.47875945]\n",
      " [0.62954939 0.37045061]\n",
      " [0.5406272  0.4593728 ]\n",
      " [0.56890459 0.43109541]\n",
      " [0.44774221 0.55225779]\n",
      " [0.42775658 0.57224342]\n",
      " [0.4544712  0.5455288 ]\n",
      " [0.62739798 0.37260202]\n",
      " [0.65259189 0.34740811]\n",
      " [0.55291484 0.44708516]\n",
      " [0.58297843 0.41702157]\n",
      " [0.56354759 0.43645241]\n",
      " [0.44527025 0.55472975]\n",
      " [0.45618415 0.54381585]\n",
      " [0.51099055 0.48900945]\n",
      " [0.52944538 0.47055462]\n",
      " [0.48738163 0.51261837]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "X = df[[\"tokens\"]]\n",
    "y = df[\"Target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# make into sparse matrices\n",
    "\"\"\"\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train[\"tokens\"].apply(lambda x: \" \".join(x)))\n",
    "X_test = vectorizer.transform(X_test[\"tokens\"].apply(lambda x: \" \".join(x)))\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "\"\"\"\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train[\"tokens\"].apply(lambda x: \" \".join(x)))\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test[\"tokens\"].apply(lambda x: \" \".join(x)))\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# print multinomial probabilities \n",
    "print(clf.predict_proba(X_test_tfidf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_all_tfidf = tfidf_vectorizer.fit_transform(X[\"tokens\"].apply(lambda x: \" \".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m----> 2\u001b[0m X_all_tfidf \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/pandas/core/frame.py:9433\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9422\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9424\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9426\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9431\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9432\u001b[0m )\n\u001b[0;32m-> 9433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m----> 2\u001b[0m X_all_tfidf \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(X\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "X = df[[\"tokens\"]]\n",
    "X_all_tfidf = tfidf_vectorizer.transform(X.apply(lambda x: \" \".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0\n",
       "0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probs = pd.DataFrame(X_all_tfidf)\n",
    "# df_probs['Original_Index'] = df.index\n",
    "df_probs\n",
    "# df_probs = pd.DataFrame(X_train_tfidf)\n",
    "# df_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285790</td>\n",
       "      <td>0.714210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561987</td>\n",
       "      <td>0.438013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.651604</td>\n",
       "      <td>0.348396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.293613</td>\n",
       "      <td>0.706387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.245220</td>\n",
       "      <td>0.754780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.706032</td>\n",
       "      <td>0.293968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.669798</td>\n",
       "      <td>0.330202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.215550</td>\n",
       "      <td>0.784450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.702527</td>\n",
       "      <td>0.297473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.323459</td>\n",
       "      <td>0.676541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   0.285790  0.714210\n",
       "1   0.561987  0.438013\n",
       "2   0.651604  0.348396\n",
       "3   0.293613  0.706387\n",
       "4   0.245220  0.754780\n",
       "..       ...       ...\n",
       "84  0.706032  0.293968\n",
       "85  0.669798  0.330202\n",
       "86  0.215550  0.784450\n",
       "87  0.702527  0.297473\n",
       "88  0.323459  0.676541\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict_proba(X_train_tfidf)\n",
    "preds = pd.DataFrame(preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 5654)\\t0.007378026118317202\\n  (0, 3260)...</td>\n",
       "      <td>0.285790</td>\n",
       "      <td>0.714210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 6194)\\t0.010016728879902891\\n  (0, 5031)...</td>\n",
       "      <td>0.561987</td>\n",
       "      <td>0.438013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 2787)\\t0.011739492812981702\\n  (0, 6204)...</td>\n",
       "      <td>0.651604</td>\n",
       "      <td>0.348396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 6312)\\t0.027695082659815715\\n  (0, 3369)...</td>\n",
       "      <td>0.293613</td>\n",
       "      <td>0.706387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 6750)\\t0.013847353309413953\\n  (0, 2800)...</td>\n",
       "      <td>0.245220</td>\n",
       "      <td>0.754780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>(0, 13)\\t0.056053053512677316\\n  (0, 6494)\\t...</td>\n",
       "      <td>0.706032</td>\n",
       "      <td>0.293968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>(0, 8333)\\t0.0708769803392585\\n  (0, 9825)\\t...</td>\n",
       "      <td>0.669798</td>\n",
       "      <td>0.330202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>(0, 8971)\\t0.01781858907958294\\n  (0, 7785)\\...</td>\n",
       "      <td>0.215550</td>\n",
       "      <td>0.784450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>(0, 3478)\\t0.06433656076681565\\n  (0, 8065)\\...</td>\n",
       "      <td>0.702527</td>\n",
       "      <td>0.297473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>(0, 9462)\\t0.060220579763797896\\n  (0, 1861)...</td>\n",
       "      <td>0.323459</td>\n",
       "      <td>0.676541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0         0         1\n",
       "0     (0, 5654)\\t0.007378026118317202\\n  (0, 3260)...  0.285790  0.714210\n",
       "1     (0, 6194)\\t0.010016728879902891\\n  (0, 5031)...  0.561987  0.438013\n",
       "2     (0, 2787)\\t0.011739492812981702\\n  (0, 6204)...  0.651604  0.348396\n",
       "3     (0, 6312)\\t0.027695082659815715\\n  (0, 3369)...  0.293613  0.706387\n",
       "4     (0, 6750)\\t0.013847353309413953\\n  (0, 2800)...  0.245220  0.754780\n",
       "..                                                ...       ...       ...\n",
       "84    (0, 13)\\t0.056053053512677316\\n  (0, 6494)\\t...  0.706032  0.293968\n",
       "85    (0, 8333)\\t0.0708769803392585\\n  (0, 9825)\\t...  0.669798  0.330202\n",
       "86    (0, 8971)\\t0.01781858907958294\\n  (0, 7785)\\...  0.215550  0.784450\n",
       "87    (0, 3478)\\t0.06433656076681565\\n  (0, 8065)\\...  0.702527  0.297473\n",
       "88    (0, 9462)\\t0.060220579763797896\\n  (0, 1861)...  0.323459  0.676541\n",
       "\n",
       "[89 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = pd.concat([df_probs, preds], axis=1)\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtfidf_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x)))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/pandas/core/frame.py:3960\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3957\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3958\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3959\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3960\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/pandas/core/frame.py:4153\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4156\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4157\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4158\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4159\u001b[0m     ):\n\u001b[1;32m   4160\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/pandas/core/frame.py:4880\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4880\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4881\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/pandas/core/common.py:575\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequire_length_match\u001b[39m(data, index: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m    Check the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow_test/lib/python3.10/site-packages/scipy/sparse/_base.py:345\u001b[0m, in \u001b[0;36mspmatrix.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix length is ambiguous; use getnnz()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or shape[0]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "\n",
    "df[\"tfidf_score\"] = tfidf_vectorizer.transform(df[\"tokens\"].apply(lambda x: \" \".join(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"tokens\"], result_df['Target'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
